{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u\"\"\"Unlike NLTK, which is widely used for teaching and research, spaCy focuses on providing software for production usage.[6][7] As of version 1.0, spaCy also supports deep learning workflows[8] that allow connecting statistical models trained by popular machine learning libraries like TensorFlow, Keras, Scikit-learn or PyTorch.[9] spaCy's machine learning library, Thinc, is also available $ as a separate open-source Python library.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unlike.................ADP...........prep\n",
      "NLTK...............PROPN...........pobj\n",
      ",...............PUNCT..........punct\n",
      "which................PRON......nsubjpass\n",
      "is.................AUX........auxpass\n",
      "widely.................ADV.........advmod\n",
      "used................VERB..........relcl\n",
      "for.................ADP...........prep\n",
      "teaching................NOUN...........pobj\n",
      "and...............CCONJ.............cc\n",
      "research................NOUN...........conj\n",
      ",...............PUNCT..........punct\n",
      "spaCy...............PROPN..........nsubj\n",
      "focuses................VERB...........ROOT\n",
      "on.................ADP...........prep\n",
      "providing................VERB..........pcomp\n",
      "software................NOUN...........dobj\n",
      "for.................ADP...........prep\n",
      "production................NOUN...........pobj\n",
      "usage.[6][7...............PROPN...........dobj\n",
      "]...............PUNCT..........punct\n",
      "As...............SCONJ...........prep\n",
      "of.................ADP...........prep\n",
      "version................NOUN...........pobj\n",
      "1.0.................NUM.........nummod\n",
      ",...............PUNCT..........punct\n",
      "spaCy...............PROPN..........nsubj\n",
      "also.................ADV.........advmod\n",
      "supports................VERB...........ROOT\n",
      "deep.................ADJ...........amod\n",
      "learning................NOUN.......compound\n",
      "workflows[8...............PROPN...........dobj\n",
      "]...............PUNCT..........punct\n",
      "that................PRON..........nsubj\n",
      "allow................VERB...........ROOT\n",
      "connecting................VERB...........amod\n",
      "statistical.................ADJ...........amod\n",
      "models................NOUN...........dobj\n",
      "trained................VERB............acl\n",
      "by.................ADP..........agent\n",
      "popular.................ADJ...........amod\n",
      "machine................NOUN.......compound\n",
      "learning................VERB.......compound\n",
      "libraries................NOUN...........pobj\n",
      "like...............SCONJ...........prep\n",
      "TensorFlow...............PROPN...........pobj\n",
      ",...............PUNCT..........punct\n",
      "Keras...............PROPN...........conj\n",
      ",...............PUNCT..........punct\n",
      "Scikit...............PROPN.......npadvmod\n",
      "-...............PUNCT..........punct\n",
      "learn................VERB...........conj\n",
      "or...............CCONJ.............cc\n",
      "PyTorch.[9................NOUN...........conj\n",
      "]...............PUNCT..........punct\n",
      "spaCy...............PROPN...........poss\n",
      "'s................PART...........case\n",
      "machine................NOUN.......compound\n",
      "learning................VERB.......compound\n",
      "library...............PROPN..........nsubj\n",
      ",...............PUNCT..........punct\n",
      "Thinc...............PROPN..........appos\n",
      ",...............PUNCT..........punct\n",
      "is.................AUX...........ROOT\n",
      "also.................ADV.........advmod\n",
      "available.................ADJ..........acomp\n",
      "$.................SYM.......npadvmod\n",
      "as...............SCONJ...........prep\n",
      "a.................DET............det\n",
      "separate.................ADJ...........amod\n",
      "open.................ADJ...........amod\n",
      "-...............PUNCT..........punct\n",
      "source................NOUN.......compound\n",
      "Python...............PROPN.......compound\n",
      "library................NOUN...........pobj\n",
      "................PUNCT..........punct\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(f\"{token.text}{token.pos_:.>{20}}{token.dep_:.>{15}}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tagger', <spacy.pipeline.pipes.Tagger at 0x21d42332c50>),\n",
       " ('parser', <spacy.pipeline.pipes.DependencyParser at 0x21d4248aa68>),\n",
       " ('ner', <spacy.pipeline.pipes.EntityRecognizer at 0x21d4248aac8>)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tagger', 'parser', 'ner']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = doc[10:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "research, spaCy focuses on"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.span.Span"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unlike NLTK, which is widely used for teaching and research, spaCy focuses on providing software for production usage.[6][7]\n",
      "As of version 1.0, spaCy also supports deep learning workflows[8]\n",
      "that allow connecting statistical models trained by popular machine learning libraries like TensorFlow, Keras, Scikit-learn or PyTorch.[9]\n",
      "spaCy's machine learning library, Thinc, is also available $ as a separate open-source Python library.\n"
     ]
    }
   ],
   "source": [
    "for sentences in doc.sents:\n",
    "    print(sentences) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
